{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from neural_network import *\n",
    "\n",
    "# read dataset\n",
    "dataset_path = 'sonar.all-data'\n",
    "# number of features\n",
    "n_features = 60\n",
    "# name the feature and target columns\n",
    "data = pd.read_csv(dataset_path, sep=\",\", names=np.append(np.arange(n_features),['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ir to dataframe\n",
    "trainset = pd.DataFrame(data)\n",
    "\n",
    "# transform Minerals in 0 and Rocks in 1\n",
    "trainset = trainset.replace('M',0)\n",
    "trainset = trainset.replace('R',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "class NNetwork:\n",
    "    def __init__(self, n_input, hidden_layer_size, n_cat):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden_layers = 2\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.n_cat = n_cat\n",
    "        \n",
    "        # initialize weights\n",
    "        self.w_1 = np.random.randn(self.hidden_layer_size, self.n_input) / np.sqrt(self.n_input)\n",
    "        self.w_2 = np.random.randn(self.hidden_layer_size, self.hidden_layer_size) / np.sqrt(self.hidden_layer_size)\n",
    "        self.w_3 = np.random.randn(self.n_cat, self.hidden_layer_size) / np.sqrt(self.hidden_layer_size)\n",
    "\n",
    "        # initialize biases\n",
    "        self.b_1 = np.zeros((self.hidden_layer_size, 1))\n",
    "        self.b_2 = np.zeros((self.hidden_layer_size, 1))\n",
    "        self.b_3 = np.zeros((self.n_cat, 1))\n",
    "        \n",
    "    def train(self, trainset_i, n_epochs, alpha, n_samples):\n",
    "        \"\"\"\n",
    "        train a fully connected neural network using the specified train_set (dataframe)\n",
    "        \"\"\"\n",
    "        if (trainset_i).shape[1]-1 != self.n_input:\n",
    "            raise ValueError(u\"X_train size has to be the same as the Network inputs\")\n",
    "\n",
    "        i = 0\n",
    "        cost = np.zeros(n_epochs)\n",
    "\n",
    "        while i < n_epochs:            \n",
    "            subset = trainset_i.sample(n_samples)\n",
    "            for index, element in trainset_i.iterrows():\n",
    "                \n",
    "                X_train = element[:-1]\n",
    "                Y_train = element[self.n_input]\n",
    "                dim1 = X_train.shape\n",
    "                \n",
    "                element = X_train.values.reshape((dim1[0], 1))\n",
    "             \n",
    "                z_1 = self.w_1.dot(element) + self.b_1    # input weight\n",
    "                a_1 = self.__relu(z_1)                   # pass through ReLU non-linearity\n",
    "\n",
    "                # pass trough the hidden layer 1\n",
    "                z_2 = self.w_2.dot(a_1) + self.b_2\n",
    "                a_2 = self.__relu(z_2)               \n",
    "\n",
    "                # pass though the hidden layer 2\n",
    "                z_3 = self.w_3.dot(a_2) + self.b_3\n",
    "                # Activation function\n",
    "                a_3 = self.__sigmoid(z_3) # predict class probabilities with the softmax activation function\n",
    "                # Loss\n",
    "                Yh = a_3\n",
    "                \n",
    "                \n",
    "                loss = self.__squared_loss(Yh, Y_train)\n",
    "                cost[i] += loss\n",
    "               \n",
    "                # derivative of the loss function w.r.t. output a_3\n",
    "                dLoss_Yh = Yh - Y_train\n",
    "\n",
    "                dLoss_z3 = dLoss_Yh * self.__dev_sigmoid(z_3)\n",
    "                dLoss_a2 = np.dot(self.w_3.T, dLoss_z3)\n",
    "                dLoss_w3 = 1./a_2.shape[0] * np.dot(dLoss_z3, a_2.T)\n",
    "                dLoss_b3 = 1./a_2.shape[0] * np.dot(dLoss_z3, np.ones([dLoss_z3.shape[1],1]))\n",
    "                \n",
    "                # 2nd layer\n",
    "                dLoss_z2 = dLoss_a2 * self.__relu_derivative(z_2)        \n",
    "                dLoss_a1 = np.dot(self.w_2.T, dLoss_z2)\n",
    "                dLoss_w2 = 1./a_1.shape[1] * np.dot(dLoss_z2, a_1.T)\n",
    "                dLoss_b2 = 1./a_1.shape[1] * np.dot(dLoss_z2, np.ones([dLoss_z2.shape[1],1]))\n",
    "                \n",
    "                # 1st layer\n",
    "                dLoss_z1 = dLoss_a1 * self.__relu_derivative(z_1)        \n",
    "                dLoss_a0 = np.dot(self.w_1.T,dLoss_z1)\n",
    "                dLoss_w1 = 1./element.shape[1] * np.dot(dLoss_z1, element.T)\n",
    "                dLoss_b1 = 1./element.shape[1] * np.dot(dLoss_z1, np.ones([dLoss_z1.shape[1],1]))\n",
    "\n",
    "                # Update the weight and biases\n",
    "                self.w_1 = self.w_1 - dLoss_w1 * alpha\n",
    "                self.b_1 = self.b_1 - dLoss_b1 * alpha\n",
    "                self.w_2 = self.w_2 - dLoss_w2 * alpha\n",
    "                self.b_2 = self.b_2 - dLoss_b2 * alpha\n",
    "                self.w_3 = self.w_3 - dLoss_w3 * alpha\n",
    "                self.b_3 = self.b_3 - dLoss_b3 * alpha\n",
    "                \n",
    "                params = [self.w_1, self.b_1, self.w_2, self.b_2, self.w_3, self.b_3]\n",
    "\n",
    "            i += 1\n",
    "        to_save = [params, cost/float(n_samples)]\n",
    "    \n",
    "        with open('model', 'wb') as file:\n",
    "            pickle.dump(to_save, file)\n",
    "\n",
    "        return cost\n",
    "    \n",
    "    def predict(self, element, w1, b1, w2, b2, w3, b3):\n",
    "        '''\n",
    "        Make predictions with trained filters/weights. \n",
    "        '''\n",
    "        element = element[:-1]\n",
    "        fc = element.values.reshape((60, 1)) # flatten pooled layer\n",
    "\n",
    "        z1 = w1.dot(fc) + b1 # first dense layer\n",
    "        a1 = self.__relu(z1) # pass through ReLU non-linearity\n",
    "\n",
    "        z2 = w2.dot(a1) + b2 # first dense layer\n",
    "        a2 = self.__relu(z2) # pass through ReLU non-linearity\n",
    "\n",
    "        out = w3.dot(a2) + b3 # second dense layer\n",
    "        probs = self.__sigmoid(out) # predict class probabilities with the softmax activation function\n",
    "\n",
    "        return (np.argmax(probs), np.max(probs))\n",
    "    \n",
    "    #### private methods\n",
    "    \n",
    "    def __squared_loss(self, probs, labels):\n",
    "        return np.sum((probs - labels)**2)*0.5\n",
    "    \n",
    "    def __relu_derivative(self, x):\n",
    "        x[x<=0] = 0\n",
    "        x[x>0] = 1\n",
    "        return x\n",
    "    \n",
    "    def __relu(self, X):\n",
    "        return np.maximum(0,X)\n",
    "\n",
    "    def __sigmoid(self, Z):\n",
    "        return 1/(1+np.exp(-Z))\n",
    "    \n",
    "    def __dev_sigmoid(self, Z):\n",
    "        s = 1/(1+np.exp(-Z))\n",
    "        dZ = s * (1-s)\n",
    "        return dZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network:\n",
    "n_neurons_per_hidden_layer = 180\n",
    "n_categories = 2\n",
    "network = NNetwork(n_features, n_neurons_per_hidden_layer, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "# trainset with features in the first 60 columns and the labels in the last one\n",
    "n_epoch = 500\n",
    "alpha = 0.1\n",
    "bach_size = 32\n",
    "\n",
    "cost = network.train(trainset, n_epoch, alpha, bach_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot cost \n",
    "plt.plot(cost, 'r')\n",
    "plt.xlabel('# Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend('Loss', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# load saved parameters\n",
    "params, cost = pickle.load(open('model', 'rb'))\n",
    "[w_1, b_1, w_2, b_2, w_3, b_3] = params\n",
    "\n",
    "# predict using the learned model\n",
    "prediction = np.array([])\n",
    "for i in np.arange(trainset.shape[0]):\n",
    "    prediction = np.append(prediction, network.predict(trainset.iloc[i], w_1, b_1, w_2, b_2, w_3, b_3)[0])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6009615384615384\n",
      "Precision 0.4536082474226804\n",
      "Recall 0.5945945945945946\n"
     ]
    }
   ],
   "source": [
    "TP = TN = FP = FN = 0\n",
    "for i in np.arange(len(prediction)):\n",
    "    TP += trainset[\"Y\"][i]==prediction[i] and trainset[\"Y\"][i] == 1\n",
    "    TN += trainset[\"Y\"][i]==prediction[i] and trainset[\"Y\"][i] == 0\n",
    "    FP += not(trainset[\"Y\"][i]==prediction[i]) and trainset[\"Y\"][i] == 1\n",
    "    FN += not(trainset[\"Y\"][i]==prediction[i]) and trainset[\"Y\"][i] == 0\n",
    "Accuracy = (TP + TN) / float(len(prediction))\n",
    "Precision = TP / float(TP + FP)\n",
    "Recall = TP / float(TP + FN)\n",
    "\n",
    "print(\"Accuracy\", Accuracy)\n",
    "print(\"Precision\", Precision)\n",
    "print(\"Recall\", Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
